# Introducci√≥n al Testing

üß™ [Introducci√≥n al Testing con JEST ‚úÖ (Bootcamp FullStack) - midudev](https://www.youtube.com/watch?v=_DzBez4qMi0)

La forma m√°s simple de entender el testing es pensando que nos permitir√° comprobar el correcto funcionamiento de un m√©todo.

Es importante que los tests sean predecibles, que no dependan de factores externos de modo tal que siempre que los ejecute obtenga el mismo resultado.

A la hora de crear tests es importante verificar que fallan pues quiz√°s nunca falle y eso lo convertir√≠a en un test in√∫til.

Supongamos que tenemos:

```javascript
const suma = (a,b) => {
  return a-b;
}
```

Si bien en este caso podemos darnos cuenta f√°cilmente qu√© est√° mal, en ocasiones ser√° mucho m√°s dif√≠cil notarlo. 

La importancia de los tests est√° no s√≥lo en saber si nuestro m√©todo funciona o no, sino que tambi√©n nos permite documentar estos m√©todos .

## Test en RunJS

Para testear este m√©todo de manera manual, podemos hacerlo en un entorno controlado utilizando **RunJS** que act√∫a como banco de pruebas o playground. 

Bastar√° con ingresar `suma(1,2) === 3` y nos aparecer√° `false` lo cual nos da la pauta de que no est√° funcionando correctamente.

Otra forma de plantearlo podr√≠a ser `if(suma(1,2)!==3) console.log('suma of 1 and 2 expected to be 3')` o bien tirando un error para hacerlo m√°s sem√°ntico `if(suma(1,2)!==3) new Error('suma of 1 and 3 expected to be 3')`

Sin embargo puede que para otras condiciones el m√©todo s√≠ funcione, por ejemplo si pusi√©ramos como argumentos 0 y 0 el `if(suma(0,0)!==0) new Error('suma of 0 and 0 expected to be 0')` no ser√≠a ejecutado ya que da el valor esperado.



## Test en Node

Para testear esto mismo tambi√©n manualmente pero directo en el proyecto de Express creamos una carpeta `tests ` y un archivo `suma.test.js`.

Haremos uso del m√©todo `console.assert()` con el cual aseveramos que una cosa dar√° cierto valor y en caso de que no se cumpla mostraremos un mensaje de error. Si lo que le pasamos como primer par√°metro es `false` saldr√° el error que le pasemos como segundo par√°metro.

```javascript
const suma = (a,b) => {
  return a-b
}

console.assert(
    suma(0,0)===3,
    'Suma of 0 and 0 expected to be 0'
)

console.assert(
    suma(1,2)===3,
    'Suma of 1 and 2 expected to be 3'
)
```



Luego para ejecutar este test 

```
node tests/suma.test.js
```

Nos aparecer√° ese mensaje de error s√≥lo en caso de que la aseveraci√≥n falle.



Lo ideal ser√≠a probar mas casos y eso podemos hacerlo empleando un array.

```javascript
const suma = (a,b) => {
  return a-b
}

const checks = [
	{ a: 0, b:0, result:0},
	{ a: 1, b:2, result:3},
	{ a: -3, b:3, result:0},
];

checks.forEach(check => {
	const {a,b,result} = check;
	console.assert(
    suma(a,b)===result,
    `Suma of ${a} and ${b} expected to be ${result}`
)
})

console.log(`${checks.length}` checks performed...);
```

Si bien podr√≠amos ampliar la informaci√≥n devuelta en el mensaje de error para aportar mas datos, esto no tiene sentido pues existen herramientas que se encargan de ejecutar una tanda de tests y entregarnos un error detallado que nos permita saber d√≥nde est√°n los fallos y solucionarlos.



## Testing con Jest 

Jest es un testing framework o *test runner* que inicialmente fue desarrollado para hacer testing en el navegador y luego evolucion√≥ siendo posible utilizarlo en servidor.

```
npm install jest -D
```

> Mocha y AVA son otras alternativas que al igual que Jest son frameworks de testing que podr√≠amos haber elegido.



Supongamos que tenemos una serie de m√©todos que queremos testear en `utils/for_testing.js`. Si tuvi√©ramos que testearlos utilizando `console.assert()` esto ser√≠a complejo por lo que utilizaremos Jest. 

Como vamos a probar un m√©todo en concreto vamos a desarrollar lo que se conoce como **test unitario**. Esto es as√≠ cuando tenemos una entrada y una salida y no produce **side effects**, ni llama a otras funciones.

```javascript
const palindrome = (string) => {
  if(typeof string === 'undefined') return;
  
  return string
    .split('')
    .reverse()
    .join('')
}

module.exports = {
  palindrome
}
```

### Configuraci√≥n Jest 

Jest como dijimos anteriormente est√° pensado para trabajar por defecto en el cliente y viene con la capacidad de simular aspectos del DOM. Esto no s√≥lo no lo necesitamos sino que puede ser problem√°tico. Es por eso que en `package.json`  vamos a colocar:

```json
"jest":{
	"testEnvironment": "node"
}
```

> Otra opci√≥n ser√≠a colocarlo en `jest.config.js` pero lo ideal es tenerlo todo en un mismo lugar as√≠ es m√°s f√°cil de encontrar y con menos archivos.

> Es posible que en Windows experimentemos problemas si el nombre de la carpeta tiene espacios (por ejemplo si nuestro nombre de usuario los tiene).



### Utilizaci√≥n Jest

> Jest por defecto buscar√° todos los archivos que terminen en `.test.js`
>
> No es necesario importar `jest` ya que una vez que encuentra este archivo sabe que debe utilizar esas dependencias.



#### Test de palindrome

En primer lugar creamos el archivo `palindrome.test.js` en la carpeta `test`.



```javascript
const {palindrome} = require('../utils/for_testing')

test ('palindrome of juaneme8', ()=> {
	const result = palindrome('juaneme8');
	
	expect(result).toBe('8emenauj');
})
test ('palindrome of empty string', ()=> {
	const result = palindrome('');
	
	expect(result).toBe('');
})
test ('palindrome of undefined', ()=> {
	const result = palindrome();
	
	expect(result).toBeUndefined();
})
```

Con `test()` estamos creando un test y lo que est√° dentro del *callback* ser√° lo que ejecutar√° para comprobar dicha prueba.

Podemos de un vistazo utilizar los tests como documentaci√≥n del m√©todo. En este caso estaremos analizando las condiciones de borde o *corner cases* como ser qu√© sucede si llamamos al m√©todo con un string vac√≠o, `undefined`, etc.



En la terminal veremos una salida similar a la siguiente:

```
‚úÖ palindrome of juaneme8
‚úÖ palindrome of empty string
‚úÖ palindrome of undefined
```

Cuando tengamos m√°s de un archivo nos convendr√° agrupar los tests de cada uno de ellos y esto lo hacemos con el m√©todo `describe()`

```js
const {palindrome} = require('../utils/for_testing')

describe('palindrome', ()=> {
    test ('of juaneme8', ()=> {
        const result = palindrome('juaneme8');

        expect(result).toBe('8emenauj');
    })
    test ('of empty string', ()=> {
        const result = palindrome('');

        expect(result).toBe('');
    })
    test ('of undefined', ()=> {
        const result = palindrome();

        expect(result).toBeUndefined();
    })
})
```

Ahora en cambio veremos

```
palindrome
    ‚úÖ of juaneme8
    ‚úÖ of empty string
    ‚úÖ of undefined
```



#### M√©todos Jest

Podemos ver la lista completa de m√©todos en la [documentaci√≥n](https://jestjs.io/docs/expect).

* `toBe()`
* `toBeNull()`
* `toBeUndefined()`
* `toEqual()`



### Configuraci√≥n Script

En `package.json` debemos modificar el script `"test"` de modo que quede de la siguiente forma:

```json
"scripts":{
	"test": "jest --verbose --silent"
}
```

> Con `--verbose` le indicamos que queremos que nos entregue la m√°xima informaci√≥n posible.
>
> Con `--silent` le indicamos que no queremos que nos muestre los `console.log()`.

Luego ejecutamos los tests con `npm run test`



### Configuraci√≥n ESLINT

Para evitar que el linter nos marque como errores el uso de `test()` y `expect() ` debemos modificar el la configuraci√≥n de eslint.

Es posible que lo tengamos en `package.json` y en ese caso debemos modificar el objeto `eslintConfig` **agregando** lo siguiente:

```json
"eslintConfig":{
	"env":{
		"jest": true,
	}
}
```



# Testing API Rest

[üî¥ Testing de Backend con Express usando Jest y Supertest - midudev](https://www.youtube.com/watch?v=_xxVJdGNMrs)



Como sabemos existen distintos tipos de tests: unitarios, de ingregraci√≥n y *end to end*. 

En este caso queremos testear una API REST y lo m√°s importante es testear a los endpoints y el efecto que generan en la base de datos por lo tanto decimos que son **tests de integraci√≥n** (incluso se podr√≠a decir que son *e2e*). No utilizamos **tests unitarios** pues estos nos servir√≠an para testear de manera aislada un m√©todo.



## Variables Entorno y Scripts

A la hora de testear el backend lo primero que debemos hacer es modificar el archivo `package.json` en particular los scripts para asegurarnos cargar con un valor distinto la variable de entorno `NODE_ENV` seg√∫n ejecutemos estemos en *development* `npm run dev`, *production* `npm start` o *testing* `npm test`.

Si estamos utilizando Windows tendremos que utilizar el paquete `cross-env`.

```json
{ 
    "scripts": {
        "dev": "cross-env NODE_ENV=development nodemon index.js",
        "start": "cross-env NODE_ENV=production node index.js",
        "test": "cross-env NODE_ENV=test jest --verbose --silent"
	},
}
```





Luego en funci√≥n del valor de `NODE_ENV` ser√° que usaremos uno u otro connection string para conectarnos a la base de datos de producci√≥n o a la de pruebas.

```javascript
const { NODE_ENV,MONGO_DB_URI,MONGO_DB_URI_TEST} = process.env;
const connectionString = NODE_ENV === 'test'
? MONGO_DB_URI_TEST
: MONGO_DB_URI;
```

> Las variables de entorno `MONGO_DB_URI` y `MONGO_DB_URI_TEST` debemos definirlas en un archivo `.env` . Para acceder a esos valores mediante `process.env` debemos tener instalado `dotenv` y colocar en `index.js` `require('dotenv').config()` en la parte de arriba. Si lo colocamos debajo de la conexi√≥n a Mongo `require('./mongo')` no obtendremos el connection string.
>
> El hecho de crear una base de datos para testing no es buena pr√°ctica y al estudiar CI/CD veremos que lo m√°s conveniente ser√≠a mockearla.


## Test de Endpoints
Como nuestro prop√≥sito es testear los endpoints, utilizaremos la biblioteca Supertest para acceder a ellos. Esta herramienta envuelve nuestro servicio de backend y nos permite testear los endponts. 

```bash
npm install supertest -D
```

Creamos un directorio `test` y en el un archivo `notes.test.js` . En esta prueba buscamos verificar que las notas de una api sean devueltas en JSON. 

Debemos tener presente que se trata de una operaci√≥n as√≠ncrona por lo que debemos esperar a que est√© el resultado disponible. Esto lo hacemos con `async` y `await`.

```js
const supertest = require('supertest');
const app = require('../index');

const api = supertest(app);

test('the result should be a json', async () => {
    await api
        .get('/api/notes')
        .expect(200)
        .expect('Content-Type', /application\/json/);
});
```



> Notar que debemos exportar `app` en`index.js`
>
> Notar que usamos una RegEx porque podemos recibir `application/json; charset=utf-8`



## Resoluci√≥n de Errores

En la consola obtenemos un mensaje que nos dice que ha terminado el test pero tenemos cosas abiertas (por ejemplo el servidor). Adem√°s nos sugiere que agreguemos la opci√≥n `--detectOpenHandles`, hacemos esto por lo que el script nos queda:

```json
"test": "cross-env NODE_ENV=test jest --verbose --silent --detectOpenHandles"
```



Para cerrar el servidor primero lo almacenamos en `server` que luego exportamos:

```js
const server = app.listen('3000', () => console.log(`Listening on Port ${PORT}`));

module.exports = { app, server };
```



Luego en el test importamos el `server` y creamos un hook  `afterAll()` con un callback para que despu√©s de todos los tests y cierre la conexi√≥n del servidor.

```js
const { app, server } = require('../index');

// todos los tests
// ...

afterAll(() => {
    moongose.connection.close()
    server.close()
})
```



> Con la versi√≥n de mongoose `6.0.9` tuve problemas para ejecutar los tests y con `--detectOpenHandles` obten√≠a **Jest has detected the following 1 open handle potentially keeping Jest from exiting: ‚óè  Timeout**. Haciendo el downgrade a la versi√≥n `5.13.9` esto se soluciona.



Una vez solucionados todos los mensajes de la consola podemos sacar el `--detectOpenHandles`

```
"test": "cross-env NODE_ENV=test jest --verbose --silent"
```



## Watch Mode

Para no tener que correr el test manualmente con `npm run test` agregamos un nuevo script que se quedar√° atento a los cambios que hagamos en los archivos y volviendo a ejecutar los tests cuando estos sucedan:

`"test:watch": "cross-env NODE_ENV=test jest --verbose --silent --watch"`



O lo que es lo mismo reutilizando el script original de test:

```
"test:watch": "npm run test -- --watch"
```

> Hacemos referencia al script anterior y queremos pasarle m√°s par√°metros. Usamos `--` y luego `--watch` porque queremos pasarle el `--watch` al comando del script `test` y no al `npm run test`



Luego con `npm run test:watch` ejecutamos los tests y a partir del pr√≥ximo cambio se ejecutar√°n autom√°ticamente.



## Saltar Tests

Si queremos que no ejecuten una serie de tests moment√°neamente podemos hacer lo siguiente:

```js
describe.skip(()=> {
	test('...', () => {
		//...
	});
	
	test('...', () => {
		//...
	});
});
```



En caso de querer saltear un test individual tambi√©n podemos hacerlo con:

```js
test.skip('...', () => {
		//...
});
```

 

> Es posible configurar una **regla del linter** que muestre warning en caso de que salteemos tests.



## Testear Archivo Espec√≠fico

En ocasiones **cuando estemos testeando un archivo y saltando los tests de otros archivos** puede resultar molesto ver en pantalla datos de los tests saltados. En esos casos podemos editar el script indicando expl√≠citamente el archivo que queremos testear:

```bash
"test": "jest --verbose --silent tests/notes.test.js"
```



Si queremos ir m√°s all√° y testear un archivo espec√≠fico y un test espec√≠fico podemos hacerlo con:

```
npm run test -- -t 'the first note should be about Juan'
```

> No es necesario poner el nombre completo podr√≠amos poner simplemente "juan" y en cualquier capitalizaci√≥n.



## Estado Inicial con `beforeEach`

Los tests deben ser **predecibles** de modo tal que siempre arrojen el mismo resultado. 

Primero verificamos que una ruta devuelve el **status code** y el **Content-Type** esperados. Sin embargo, si queremos verificar por ejemplo la cantidad de elementos devueltos por una ruta depender√≠amos de un factor externo como que alguien haya agregado un elemento a la base de datos de testing y as√≠ el test fallar√≠a.

Queremos tener la certeza de que el contenido de la base de datos es el esperado. Para ello antes de cada test borraremos todas las notas y luego agregaremos las de `initialNotes`. Esto lo hacemos utilizando el hook `beforeEach`

```js
const mongoose = require('mongoose');
const supertest = require('supertest');
const { app, server } = require('../index');
const Note = require('../models/Note');

const api = supertest(app);

const initialNotes = [
    {
        content: "Notas de Juan",
        important: true,
        date: new Date()
    },
    {
        content: "Nota de Paco",
        important: true,
        date: new Date()
    },
    {
        content: "Notas de Pedro",
        important: true,
        date: new Date()
    }
]

beforeEach(async () => {
    await Note.deleteMany({});

    const note1 = new Note(initialNotes[0])
    await note1.save()

    const note2 = new Note(initialNotes[1])
    await note2.save()

    const note3 = new Note(initialNotes[2])
    await note3.save()
})

describe('GET /api/notes', () => {
    test('there are three notes', async () => {
        const res = await api.get('/api/notes')
        expect(res.body).toHaveLength(initialNotes.length);
    });
})

afterAll(() => {
    server.close()
    mongoose.connection.close();
})
```



## Peticiones GET

Si queremos testear que el contenido de un elemento en particular tenga ciertas caracter√≠sticas:

```js
test('the first note should be about Juan', async () => {
const res = await api.get('/api/notes');

expect(res.body[0].content).toBe('Notas de Juan');
});
```

Sin embargo, muchas veces queremos verificar el contenido en cualquier posici√≥n del array devuelto por la ruta:

```js
test('there should be a note about Paco', async () => {
    const res = await api.get('/api/notes');

    const contents = res.body.map(note => note.content);

    expect(contents).toContain('Notas de Paco');
});
```



## Peticiones POST

```js
test('a new note should be added', async () => {
    const newNote = {
    content: 'Notas de De La Mar',
    important: false,
    };

    await api
    .post('/api/notes')
    .send(newNote)
    .expect(200)
    .expect('Content-Type', /application\/json/);

    const res = await api.get('/api/notes');

    const contents = res.body.map(note => note.content);

    expect(contents).toContain('Notas de De La Mar');
    expect(res.body).toHaveLength(initialNotes.length + 1);
});
```

Luego de agregar el elemento a la base de datos estamos chequeando tanto que el contenido sea el deseado como que el n√∫mero de elementos tambi√©n sea coherente.



Debemos chequear las condiciones de borde, por ejemplo que no sea posible agregar un elemento si falta un campo requerido. 

```js
test('an empty note should not be added', async () => {
    const newNote = {
    important: false,
    };
    await api.post('/api/notes').send(newNote).expect(400);

    const res = await api.get('/api/notes');
    expect(res.body).toHaveLength(initialNotes.length);
});
```



> En este caso verificamos obtener un error 400 y que no hayan sido agregados elementos a la base de datos.

  

## Test Helpers

Como podemos ver hay l√≠neas de c√≥digo que se repiten bastante, es por eso que creamos un archivo dentro de `test` llamado `helpers.js`.
